#!/usr/bin/env python3
"""
Continuous Lint Fix - Automated parallel processing of all linting errors.

This script creates a continuous workflow where subagents automatically process
files until all linting errors are resolved. When a subagent completes a file,
it immediately gets assigned the next available file.
"""

import json
import argparse
import subprocess
import time
import os
from datetime import datetime
from typing import Dict, List, Optional
from pathlib import Path

class ContinuousLintFixer:
    def __init__(self, max_concurrent: int = 5):
        self.max_concurrent = max_concurrent
        self.work_queue = []
        self.completed_files = []
        self.failed_files = []
        self.status_file = ".claude/lint-fix-status.json"
        
    def parse_lint_log(self, log_path: str) -> Dict[str, List[dict]]:
        """Parse ESLint output and group by file."""
        import re
        from collections import defaultdict
        
        file_errors = defaultdict(list)
        current_file = None
        file_pattern = re.compile(r'^\.\/(.+)$')
        error_pattern = re.compile(
            r'^(\d+):(\d+)\s+(Error|Warning):\s+(.+?)\s+(@[\w-]+/[\w-]+)$'
        )
        
        with open(log_path, 'r') as f:
            for line in f:
                line = line.strip()
                
                # New file section
                file_match = file_pattern.match(line)
                if file_match:
                    current_file = file_match.group(1)
                    continue
                
                # Error/warning line
                if current_file and error_pattern.match(line):
                    match = error_pattern.match(line)
                    file_errors[current_file].append({
                        'line': int(match.group(1)),
                        'column': int(match.group(2)),
                        'severity': match.group(3),
                        'message': match.group(4),
                        'rule': match.group(5)
                    })
        
        return dict(file_errors)
    
    def create_fix_instructions(self, file_path: str, errors: List[dict]) -> str:
        """Create detailed fix instructions for a specific file."""
        from collections import defaultdict
        
        # Group errors by rule for clearer instructions
        errors_by_rule = defaultdict(list)
        for error in errors:
            errors_by_rule[error['rule']].append(error)
        
        instructions = [
            f"Fix all {len(errors)} linting issues in: {file_path}",
            "",
            "ERRORS TO FIX:",
            ""
        ]
        
        # Add specific fix instructions based on common error patterns
        fix_guides = {
            '@typescript-eslint/no-unused-vars': 
                "Remove the unused import/variable OR prefix with underscore (_) if needed for later",
            '@typescript-eslint/unbound-method': 
                "Convert to arrow function OR add 'this: void' parameter annotation",
            '@typescript-eslint/no-unsafe-assignment': 
                "Add proper type annotations to replace 'any' types",
            '@typescript-eslint/no-unsafe-member-access': 
                "Add type guards or proper type annotations for safe access",
            '@typescript-eslint/no-explicit-any': 
                "Replace 'any' with specific type (unknown, proper interface, etc.)",
            '@typescript-eslint/restrict-template-expressions':
                "Ensure only string/number types in template literals (use String() if needed)",
            '@typescript-eslint/no-base-to-string':
                "Use proper type checking before string conversion or JSON.stringify() for objects"
        }
        
        for rule, rule_errors in errors_by_rule.items():
            instructions.append(f"{rule}: ({len(rule_errors)} occurrences)")
            
            # Add specific fix guide if available
            if rule in fix_guides:
                instructions.append(f"  Fix: {fix_guides[rule]}")
            
            # List specific instances
            for error in rule_errors[:5]:  # Show first 5 instances
                instructions.append(f"  - Line {error['line']}: {error['message']}")
            
            if len(rule_errors) > 5:
                instructions.append(f"  ... and {len(rule_errors) - 5} more")
            
            instructions.append("")
        
        instructions.extend([
            "IMPORTANT:",
            "1. Read the file first to understand context",
            "2. Fix ALL listed errors systematically", 
            "3. Maintain existing code functionality",
            "4. Follow the project's coding style",
            "5. Don't add unnecessary comments",
            "6. After fixing, report completion and automatically get next file"
        ])
        
        return "\n".join(instructions)
    
    def create_work_queue(self, file_errors: Dict[str, List[dict]]) -> List[dict]:
        """Create prioritized work queue."""
        tasks = []
        
        for file_path, errors in file_errors.items():
            error_count = sum(1 for e in errors if e['severity'] == 'Error')
            warning_count = sum(1 for e in errors if e['severity'] == 'Warning')
            
            task = {
                'file': file_path,
                'error_count': error_count,
                'warning_count': warning_count,
                'total_issues': error_count + warning_count,
                'instructions': self.create_fix_instructions(file_path, errors)
            }
            tasks.append(task)
        
        # Sort by total issues (easier files first)
        tasks.sort(key=lambda x: x['total_issues'])
        
        return tasks
    
    def save_status(self, current_status: dict):
        """Save current processing status."""
        os.makedirs(os.path.dirname(self.status_file), exist_ok=True)
        with open(self.status_file, 'w') as f:
            json.dump(current_status, f, indent=2)
    
    def load_status(self) -> Optional[dict]:
        """Load previous processing status."""
        if os.path.exists(self.status_file):
            try:
                with open(self.status_file, 'r') as f:
                    return json.load(f)
            except:
                return None
        return None
    
    def create_continuous_workflow_script(self, work_queue: List[dict]) -> str:
        """Create a script that manages continuous file processing."""
        
        total_files = len(work_queue)
        
        script_content = f'''#!/usr/bin/env python3
"""
Continuous Lint Fix Worker - Automatically processes files until all are done.
Generated on: {datetime.now().isoformat()}
"""

import json
import os
import time
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

class ContinuousWorker:
    def __init__(self):
        self.work_queue = {json.dumps(work_queue, indent=2)}
        self.completed = []
        self.failed = []
        self.queue_lock = Lock()
        self.status_file = ".claude/lint-fix-status.json"
        self.max_concurrent = {self.max_concurrent}
        
    def get_next_task(self):
        """Get the next available task from the queue."""
        with self.queue_lock:
            if self.work_queue:
                return self.work_queue.pop(0)
            return None
    
    def spawn_subagent(self, task):
        """Spawn a subagent to process a single file."""
        print(f"üîß Starting subagent for: {{task['file']}}")
        
        # Create the subagent task prompt
        prompt = f"""
{{task['instructions']}}

After completing this file, immediately check if there are more files to process.
If lint-fix-status.json shows remaining files, automatically start the next one.
Continue until all files are processed.

WORKFLOW:
1. Fix all issues in {{task['file']}}
2. Save progress to .claude/lint-fix-status.json
3. Check for next file automatically
4. Repeat until all files complete

This is part of a continuous workflow - don't stop after one file!
"""
        
        # For demonstration, we'll use a simple task simulation
        # In practice, you'd use Claude Code's Task tool here
        try:
            # Simulate processing time
            time.sleep(1 + (task['total_issues'] * 0.5))
            
            # Mark as completed
            with self.queue_lock:
                self.completed.append(task['file'])
                print(f"‚úÖ Completed: {{task['file']}}")
                
                # Update status
                self.save_status()
                
                # Check for next task
                next_task = self.get_next_task()
                if next_task:
                    print(f"üîÑ Auto-assigning next file: {{next_task['file']}}")
                    return self.spawn_subagent(next_task)
                else:
                    print("üéâ No more files in queue!")
                    
            return True
            
        except Exception as e:
            print(f"‚ùå Failed to process {{task['file']}}: {{e}}")
            with self.queue_lock:
                self.failed.append(task['file'])
                self.save_status()
            return False
    
    def save_status(self):
        """Save current processing status."""
        status = {{
            'timestamp': time.time(),
            'total_files': {total_files},
            'completed': len(self.completed),
            'failed': len(self.failed),
            'remaining': len(self.work_queue),
            'completed_files': self.completed,
            'failed_files': self.failed,
            'remaining_files': [task['file'] for task in self.work_queue]
        }}
        
        os.makedirs(os.path.dirname(self.status_file), exist_ok=True)
        with open(self.status_file, 'w') as f:
            json.dump(status, f, indent=2)
    
    def run(self):
        """Run the continuous workflow."""
        print(f"üöÄ Starting continuous lint fix workflow")
        print(f"üìä Total files: {total_files}")
        print(f"üîÑ Max concurrent: {{self.max_concurrent}}")
        print("")
        
        # Start initial batch of workers
        with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
            # Submit initial tasks
            futures = []
            for i in range(min(self.max_concurrent, len(self.work_queue))):
                task = self.get_next_task()
                if task:
                    future = executor.submit(self.spawn_subagent, task)
                    futures.append(future)
            
            # Wait for all to complete
            for future in as_completed(futures):
                try:
                    result = future.result()
                except Exception as e:
                    print(f"‚ùå Worker failed: {{e}}")
        
        # Final status
        print(f"\\nüìà Final Results:")
        print(f"‚úÖ Completed: {{len(self.completed)}}")
        print(f"‚ùå Failed: {{len(self.failed)}}")
        print(f"üìã Remaining: {{len(self.work_queue)}}")
        
        if len(self.work_queue) == 0:
            print("üéâ All files processed!")
        else:
            print("‚ö†Ô∏è  Some files remain - check status file")

if __name__ == "__main__":
    worker = ContinuousWorker()
    worker.run()
'''
        
        return script_content
    
    def create_claude_task_manager(self, work_queue: List[dict]) -> str:
        """Create a task manager that uses Claude Code's Task tool."""
        
        task_definitions = []
        for i, task in enumerate(work_queue):
            task_definitions.append({
                'id': f"task_{i}",
                'file': task['file'],
                'instructions': task['instructions'],
                'priority': task['total_issues']
            })
        
        manager_script = f'''#!/usr/bin/env python3
"""
Claude Code Task Manager - Manages continuous processing using Task tool.
"""

import json
import os
import time
from datetime import datetime

class ClaudeTaskManager:
    def __init__(self):
        self.tasks = {json.dumps(task_definitions, indent=2)}
        self.status_file = ".claude/lint-fix-status.json"
        self.max_concurrent = {self.max_concurrent}
        
    def create_task_batch_script(self):
        """Create a script that processes all tasks continuously."""
        
        script_lines = [
            "#!/bin/bash",
            "# Continuous Lint Fix - Auto-processing all files",
            "",
            f"echo 'üöÄ Starting continuous lint fix for {{len(self.tasks)}} files'",
            f"echo 'üîÑ Max concurrent: {{self.max_concurrent}}'",
            "echo ''",
            "",
            "# Function to process a single file",
            "process_file() {{",
            "    local file_path=$1",
            "    local instructions=$2",
            "    local task_id=$3",
            "    ",
            "    echo 'üîß Processing: $file_path'",
            "    ",
            "    # Here you would use Claude Code's Task tool",
            "    # For now, we'll simulate with a placeholder",
            "    echo 'Task: Fix linting errors in $file_path'",
            "    echo '$instructions'",
            "    ",
            "    # Simulate processing time",
            "    sleep 2",
            "    ",
            "    echo '‚úÖ Completed: $file_path'",
            "    ",
            "    # Update status",
            "    echo '$task_id' >> .claude/completed_tasks.log",
            "}}",
            "",
            "# Process all files with controlled concurrency",
            "export -f process_file",
            "",
        ]
        
        # Add parallel processing commands
        for i in range(0, len(self.tasks), self.max_concurrent):
            batch = self.tasks[i:i+self.max_concurrent]
            script_lines.append(f"# Batch {{i//self.max_concurrent + 1}}")
            
            for task in batch:
                file_path = task['file']
                instructions = task['instructions'].replace('\\n', '\\\\n').replace('"', '\\\\"')
                task_id = task['id']
                
                script_lines.append(f'process_file "{file_path}" "{instructions}" "{task_id}" &')
            
            script_lines.extend([
                "wait  # Wait for batch to complete",
                "echo '‚úÖ Batch completed'",
                "echo ''",
                ""
            ])
        
        script_lines.extend([
            "echo 'üéâ All files processed!'",
            "echo 'Completed tasks:'",
            "cat .claude/completed_tasks.log 2>/dev/null | wc -l",
            ""
        ])
        
        return "\\n".join(script_lines)
    
    def generate_claude_commands(self):
        """Generate specific commands for use with Claude Code."""
        
        commands = []
        
        # Create individual task commands
        for task in self.tasks:
            command = f'''
# Task: Fix {{task['file']}} ({{task['priority']}} issues)
# Use this with Claude Code's Task tool:

Task:
  description: "Fix linting errors in {{task['file']}}"
  prompt: |
    {{task['instructions']}}
    
    After completing this file:
    1. Update .claude/lint-fix-status.json with completion
    2. Check for next available file
    3. Automatically start next file if available
    4. Continue until all files are processed
'''
            commands.append(command)
        
        return commands

if __name__ == "__main__":
    manager = ClaudeTaskManager()
    
    # Generate the batch processing script
    batch_script = manager.create_task_batch_script()
    
    with open(".claude/continuous-lint-fix.sh", "w") as f:
        f.write(batch_script)
    
    os.chmod(".claude/continuous-lint-fix.sh", 0o755)
    
    print("üìù Generated continuous processing script: .claude/continuous-lint-fix.sh")
    print("üöÄ To run: ./.claude/continuous-lint-fix.sh")
    print("")
    print("Or use with Claude Code Task tool for each file individually.")
'''
        
        return manager_script

def main():
    parser = argparse.ArgumentParser(
        description="Continuous parallel lint fixing workflow"
    )
    parser.add_argument(
        "--lint-log", 
        default="lint.log",
        help="Path to ESLint output log"
    )
    parser.add_argument(
        "--max-concurrent",
        type=int,
        default=5,
        help="Maximum concurrent subagents"
    )
    parser.add_argument(
        "--output-script",
        default=".claude/continuous-lint-fix.py",
        help="Output script path"
    )
    parser.add_argument(
        "--task-manager",
        default=".claude/claude-task-manager.py",
        help="Claude task manager script path"
    )
    
    args = parser.parse_args()
    
    fixer = ContinuousLintFixer(max_concurrent=args.max_concurrent)
    
    print(f"üîç Analyzing lint log: {args.lint_log}")
    file_errors = fixer.parse_lint_log(args.lint_log)
    
    if not file_errors:
        print("‚ú® No linting errors found!")
        return
    
    print(f"üìä Found {len(file_errors)} files with linting issues")
    
    # Create work queue
    work_queue = fixer.create_work_queue(file_errors)
    
    # Generate continuous workflow script
    workflow_script = fixer.create_continuous_workflow_script(work_queue)
    
    # Save the workflow script
    os.makedirs(os.path.dirname(args.output_script), exist_ok=True)
    with open(args.output_script, 'w') as f:
        f.write(workflow_script)
    
    os.chmod(args.output_script, 0o755)
    
    # Generate Claude task manager
    task_manager_script = fixer.create_claude_task_manager(work_queue)
    
    with open(args.task_manager, 'w') as f:
        f.write(task_manager_script)
    
    os.chmod(args.task_manager, 0o755)
    
    # Show summary
    total_errors = sum(task['error_count'] for task in work_queue)
    total_warnings = sum(task['warning_count'] for task in work_queue)
    
    print(f"\\nüìà Continuous Workflow Created:")
    print(f"  Total files: {len(work_queue)}")
    print(f"  Total errors: {total_errors}")
    print(f"  Total warnings: {total_warnings}")
    print(f"  Max concurrent: {args.max_concurrent}")
    print(f"\\nüìù Generated files:")
    print(f"  Workflow script: {args.output_script}")
    print(f"  Task manager: {args.task_manager}")
    print(f"\\nüöÄ To start continuous processing:")
    print(f"  python3 {args.output_script}")
    print(f"  OR use Claude Code Task tool with files from {args.task_manager}")
    
    # Save initial status
    initial_status = {
        'timestamp': time.time(),
        'total_files': len(work_queue),
        'completed': 0,
        'failed': 0,
        'remaining': len(work_queue),
        'completed_files': [],
        'failed_files': [],
        'remaining_files': [task['file'] for task in work_queue]
    }
    
    fixer.save_status(initial_status)
    print(f"\\nüìä Status tracking: {fixer.status_file}")

if __name__ == "__main__":
    main()