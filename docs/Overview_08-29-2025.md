# Cronium Application Overview

_Date: August 29, 2025_

## Executive Summary

Cronium is a comprehensive automation platform designed for scheduling and executing scripts, workflows, and integrations across both local (containerized) and remote (SSH) environments. Built as a monorepo using modern web technologies, it provides a robust job queue system, visual workflow builder, and extensive integration capabilities through tool plugins.

## Architecture Overview

### Technology Stack

- **Frontend**: Next.js 15 (App Router), TypeScript, TailwindCSS 4, React Hook Form + Zod
- **Backend**: Node.js, tRPC, Drizzle ORM, PostgreSQL
- **Services**: Go-based orchestrator and runtime services
- **Execution**: Docker containers (local), SSH with signed runner binaries (remote)
- **Real-time**: Socket.IO/WebSockets for live updates
- **Build**: Turborepo, PNPM workspace management

### Core Components

1. **Cronium App** (`apps/cronium-app`): Main web application
2. **Orchestrator** (`apps/orchestrator`): Go service for job queue management
3. **Runtime** (`apps/runtime`): Go service providing runner binaries and helper APIs
4. **UI Package** (`packages/ui`): Shared React components

## Data Model & Schema

### Core Entities

#### Events

- Central execution unit containing scripts (Bash, Node.js, Python) or HTTP requests
- Support for scheduled, manual, or workflow-triggered execution
- Can run locally (containerized) or on remote servers via SSH
- Payload versioning for script updates

#### Jobs

- Queue entries created from events
- States: `queued` → `claimed` → `running` → `completed/failed/cancelled`
- Priority-based execution (LOW, NORMAL, HIGH, CRITICAL)
- Atomic claiming mechanism prevents duplicate processing

#### Executions

- Individual execution records for jobs
- Track per-server execution for multi-server deployments
- Store output, exit codes, and error messages
- Support partial success tracking (exit codes 100+)

#### Workflows

- Multi-step event chains with visual canvas editor
- Connection types: ALWAYS, ON_SUCCESS, ON_FAILURE, ON_CONDITION
- Parallel and sequential execution support
- Webhook and scheduled triggers

#### Logs

- Aggregated execution history
- Status tracking: PENDING, RUNNING, SUCCESS, FAILURE, TIMEOUT, PARTIAL
- Linked to jobs, executions, and workflows
- Real-time updates via WebSocket

## Execution Flow

### Event Execution Pipeline

1. **Event Creation/Trigger**
   - User creates/schedules event or workflow triggers it
   - Event configuration includes script content, environment variables, timeout

2. **Job Creation**
   - Event triggers job creation in queue
   - Job contains execution payload with script, environment, resources
   - Priority and scheduling determined

3. **Job Claiming (Orchestrator)**
   - Orchestrator polls job queue
   - Atomically claims jobs to prevent duplication
   - Routes to appropriate executor based on type

4. **Execution Routing**
   - **Container Executor**: Local Docker-based execution
   - **SSH Executor**: Remote server execution with runner binary

5. **Status Updates**
   - Real-time status updates via WebSocket
   - Log entries created and updated
   - Execution records maintained

6. **Completion**
   - Exit codes and output captured
   - Conditional actions triggered (success/failure/always)
   - Cleanup of temporary resources

### Workflow Execution

1. **Graph Analysis**
   - Identify starting nodes (no incoming connections)
   - Build execution graph with dependencies

2. **Parallel Execution**
   - Starting nodes execute in parallel
   - Each node waits for prerequisites based on connection conditions

3. **Node Execution**
   - Each node executes its associated event
   - Results propagated through connections
   - Script output and conditions passed downstream

4. **Aggregation**
   - All node results aggregated
   - Workflow marked success if all nodes succeed
   - Detailed execution history maintained

## Execution Environments

### Containerized Execution (Local)

- **Isolation**: Each job runs in isolated Docker container
- **Resource Limits**: CPU, memory, disk, PID limits enforced
- **Sidecar Pattern**: Helper container provides runtime API
- **Network Isolation**: Optional network isolation for security
- **Automatic Cleanup**: Containers removed after execution

**Container Features:**

- Full runtime helper support (cronium.input, cronium.output, etc.)
- Volume mounts for script and data
- Environment variable injection
- Timeout enforcement
- Live log streaming

### SSH Execution (Remote)

- **Runner Binary**: Go-compiled binary deployed to servers
- **Signed Tokens**: JWT authentication for secure execution
- **Payload System**: Scripts packaged as tar.gz with manifest
- **Multi-Server**: Parallel execution across server pools
- **Cleanup**: Automatic removal of runners and payloads

**SSH Features:**

- Connection pooling for performance
- Circuit breaker for fault tolerance
- Runner caching to avoid re-deployment
- Checksum verification for integrity
- Progress tracking and live output

## Job Queue System

### Queue Architecture

- **Database-backed**: PostgreSQL for persistent queue
- **Priority Scheduling**: Four-level priority system
- **Atomic Operations**: Prevent race conditions
- **Retry Logic**: Exponential backoff for failures
- **Dead Letter Queue**: Failed jobs after max retries

### Job Lifecycle

```
Created → Queued → Claimed → Running → Completed/Failed
                     ↓         ↓
                  Released  Cancelled
```

### Orchestrator Responsibilities

- Poll job queue at configurable intervals
- Claim jobs atomically
- Route to appropriate executor
- Track execution progress
- Update job status and results
- Handle cleanup and recovery

## Logging & Monitoring

### Log Aggregation

- **Event Logs**: Individual event execution history
- **Workflow Logs**: Aggregated workflow execution logs
- **Job Logs**: Queue and execution tracking
- **Tool Action Logs**: Integration execution audit

### Multi-Server Log Aggregation

- Execution records per server
- Partial success detection (some servers succeed)
- Combined output aggregation
- Exit code mapping (100+ for partial success)

### Real-time Updates

- WebSocket broadcast for live log streaming
- Status changes pushed to connected clients
- Progress tracking for long-running jobs
- Terminal output for interactive sessions

## Tool Plugins Architecture

### Plugin System

- **Extensible**: Support for custom tool integrations
- **Credential Management**: Encrypted storage of API keys
- **OAuth Support**: Token management for OAuth providers
- **Rate Limiting**: Built-in rate limit management
- **Circuit Breaking**: Fault tolerance for external services

### Supported Integrations

- **Communication**: Slack, Discord, Microsoft Teams, Email
- **Version Control**: GitHub, GitLab, Bitbucket
- **Cloud Providers**: AWS, GCP, Azure
- **Monitoring**: Datadog, PagerDuty, Opsgenie
- **Databases**: PostgreSQL, MySQL, MongoDB
- **Custom Webhooks**: Generic HTTP integrations

### Action Execution

1. **Parameter Validation**: Zod schemas for type safety
2. **Credential Retrieval**: Decryption and cache management
3. **Connection Pooling**: Reuse connections where possible
4. **Error Categorization**: Transient vs permanent failures
5. **Retry Strategy**: Configurable retry policies
6. **Audit Logging**: Track all tool actions

## Runtime Helpers

### Available Functions

- `cronium.input()`: Retrieve input from previous events
- `cronium.output()`: Pass data to subsequent events
- `cronium.getVariable()`: Access user-defined variables
- `cronium.setVariable()`: Update variables
- `cronium.event()`: Access current event metadata
- `cronium.log()`: Structured logging with levels
- `cronium.sleep()`: Delay execution
- `cronium.fetch()`: HTTP requests with authentication

### Implementation

- **Container Mode**: Direct API calls to sidecar container
- **SSH Mode**: API callbacks to runtime service
- **Authentication**: JWT tokens for secure communication
- **Data Persistence**: Variables stored in database

## UI Components & Structure

### Page Structure

```
/dashboard
  ├── /events       - Event management
  ├── /workflows    - Visual workflow builder
  ├── /servers      - Server configuration
  ├── /logs         - Execution history
  ├── /jobs         - Job queue monitoring
  ├── /tools        - Integration management
  ├── /settings     - User preferences
  └── /admin        - System administration
```

### Key Components

- **EventForm**: Complex form with code editor, scheduling, conditions
- **WorkflowCanvas**: React Flow-based visual editor
- **CodeEditor**: Monaco editor with language support
- **LogDetail**: Real-time log viewer with WebSocket updates
- **JobsTable**: Queue monitoring with filters
- **Terminal**: xterm.js interactive shell

### State Management

- **tRPC**: Type-safe API calls
- **React Query**: Server state management
- **React Hook Form**: Form state with validation
- **Zustand**: Client-side state for complex UIs

## Security Features

### Authentication & Authorization

- **Next-Auth**: Email/password authentication
- **Role-Based Access**: Admin, User, Viewer roles
- **API Tokens**: Programmatic access
- **Session Management**: Secure cookie-based sessions

### Data Protection

- **Encryption**: Sensitive data encrypted at rest
- **SSH Keys**: Secure storage and management
- **Signed Binaries**: Runner integrity verification
- **Network Isolation**: Optional container network isolation

### Audit & Compliance

- **Audit Logs**: Comprehensive action tracking
- **Tool Usage Metrics**: Integration monitoring
- **Rate Limiting**: Prevent abuse
- **IP Whitelisting**: Webhook security

## Performance Optimizations

### Code Splitting

- Lazy loading for heavy components (Monaco, Terminal)
- Dynamic imports for workflow canvas
- Route-based code splitting

### Caching Strategies

- **Runner Cache**: Avoid re-deployment to SSH servers
- **Credential Cache**: Reduce decryption overhead
- **Connection Pooling**: Reuse SSH/database connections
- **Auth Cache**: Session caching for performance

### Background Processing

- **Job Polling Service**: Efficient queue processing
- **Workflow Cleanup**: Automatic resource cleanup
- **Payload Management**: Periodic cleanup of old files

## Deployment Considerations

### Environment Variables

- **DATABASE_URL**: PostgreSQL connection
- **ENCRYPTION_KEY**: Data encryption key
- **JWT_SECRET**: Token signing secret
- **API_TOKEN**: Service authentication
- **RUNTIME_HOST/PORT**: Runtime service location

### Docker Deployment

- Multi-stage builds for optimization
- Docker Compose for local development
- Kubernetes-ready with health checks
- Volume mounts for persistent data

### Scaling Considerations

- Horizontal scaling of orchestrator instances
- Database connection pooling
- Redis/Valkey for session storage
- CDN for static assets

## Current State & Known Areas

### Strengths

- Robust job queue with atomic operations
- Flexible execution environments
- Visual workflow builder
- Extensive integration capabilities
- Real-time updates and monitoring

### Areas for Attention

- Workflow execution graph optimization
- Multi-server log aggregation refinement
- Tool action error handling improvements
- Performance optimization for large-scale deployments

## Conclusion

Cronium provides a comprehensive automation platform with enterprise-grade features while maintaining simplicity for self-hosted deployments. The architecture supports both simple script execution and complex multi-step workflows, with robust error handling, monitoring, and integration capabilities. The modular design allows for easy extension and customization while maintaining reliability and performance.
